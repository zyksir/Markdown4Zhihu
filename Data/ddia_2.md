## 数据密集型应用设计(DDIA)阅读笔记(2)

ddia中文翻译网址：https://github.com/Vonng/ddia

**加粗的小标题我觉得章节讨论的点**

普通的文字是内容的总结

> 灰灰的是我个人的一些想法+吐槽

### 第三章 存储和检索

本章解决的核心问题：有哪几种存储&检索数据的方式？它们之间的优缺点分别是什么？

##### 关键值索引有哪些

- 哈希索引：
  - 数据存储：采用仅追加的方式
  - 索引：将键哈希映射到数据文件中的字节偏移量。这就要求索引必须能完全放在内存里。
  - 如何有效的利用空间：压缩日志文件，丢弃重复键更新 log 而只保留每个键的最近更新
  - 容错性：数据库崩溃了-》在内存中的索引会丢失，但是我们可以遍历磁盘中数据重构索引
  - 优点：由于是顺序写入，写入速度很快；并发读取和崩溃处理很简单
  - 缺点：范围查询效率不佳，想查询 zyk1~zyk99的所有键就要做99次映射；如果键的数目很多会出发哈希映射的短板，也就是随机 IO 带来的开销 & 散列冲突

- LSM 树：
  - 数据存储：以排序字符串表 SSTable的方式，更新时只需要归并即可
  - 索引：内存中用平衡树存键到偏移量的映射，当内存表比较大的时候再写入磁盘
  - 容错性：每次写的时候会往磁盘中顺序写入一个日志，该日志用于崩溃后恢复；当内存表写入 SSTable 时可以丢弃该日志
  - 补充：查询是，我们会去一个段一个段的检查；具体的，对每个段，使用 bloom 过滤器快速该段包含的数据中是否有该键。另外，如何&何时压缩、合并也挺重要的，不同数据库采用了不同的方式
  - 优点：具有较高的写入速度(可以顺序写入紧凑的 SSTable 文件，而 B 树就要覆盖页面)；具有较低的存储开销(不像 B 树那样留下未使用的磁盘空间)；同时即使数据集比内存大的多，也可以工作
  - 缺点：LSM 树由于压缩在后台进行，就容易占用磁盘带宽；如果写入吞吐很高，还会占用导致合并跟不上写入

- B 树：
  - 数据存储：将数据库分解成大小固定的块或者页面...不概括了懂的都懂；
  - 容错性：和LSM树差不多，有一个预写式日志用于恢复，平时仅追加；
  - 如何处理并发：通过轻量级的锁
  - 优点：B 树的行为更具有可预测性，因为每个键是没有冗余的
  - 缺点：写放大，即可能就写入一个值，但是导致了B树的分裂，产生了很大的延迟
  - 一个经验性的结论：LSM写入速度快，B树读取速度快

##### 还有哪些其他索引

- 二级索引
  - 聚集索引：在索引中存行数据
  - 非聚集索引：仅在索引中存储数据引用
  - 包含列的索引：存储表的一部分在索引内

- 多列索引：R树，主要在地理空间数据的使用上，这一块书中没仔细讲实现方式。只是简单提了一句，可以讲二位位置映射成一维的一个数，然后使用B树

- 内存数据库：在内存中存储一切，磁盘仅作为永久性附加日志。也就是说其实还是要去写磁盘的！
  内存数据库更快的原因是因为省去了将内存数据结构编码为磁盘数据结构的开销
  Redis就是一个内存数据库

##### 关于检索/存储的一些概念

- 事务处理和事务分析

| 属性         | 事务处理 OLTP                | 分析系统 OLAP            |
| ------------ | ---------------------------- | ------------------------ |
| 主要读取模式 | 查询少量记录，按键读取       | 在大批量记录上聚合       |
| 主要写入模式 | 随机访问，写入要求低延时     | 批量导入（ETL），事件流  |
| 主要用户     | 终端用户，通过Web应用        | 内部数据分析师，决策支持 |
| 处理的数据   | 数据的最新状态（当前时间点） | 随时间推移的历史事件     |
| 数据集尺寸   | GB ~ TB                      | TB ~ PB                  |

- 数据仓库
  - 因为OLTP系统和OLAP系统的要求是不同的，因此拆成了两套系统。数据仓库就是专门针对分析系统设计出的。
  - 如何存储数据：抽取(从OLTP系统中提取数据) -》 转化(得到适合分析的模式) -》加载(放到数据仓库中)

- 列存储-》广泛应用于数据仓库中
  - 核心思想：将每列的值存储在一起。因为存在大量这样的场景：分析时需要用到很多数据，每个数据只需要其中几列。
  - 存储：可以压缩列数据，例如位图编码；同时存储顺序也很重要，会根据不同的场景选择选择多个排序键；而且本身我们就需要做一个数据备份，我们完全可以在几个不同版本中按照不同的排序键排序
  - 写入：使用LSM树 -》按照列排序和按照行排序会很相似

```bash
db_set () {echo "$1,$2" >> database}
db_get () {grep "^$1," database | sed -e "s/^$1,//" | tail -n 1}
```

> 文中用上述两行代码实现了一个简易数据库也太 nb 了

### 第四章 编码与演化

- 本章探讨的核心问题：如何让数据保持双向兼容性。即、如何让新代码可以读旧数据 以及 如何让旧代码可以读新数据

- 本章所探讨的编码：内存数据 到 字节序列 之间的转换。这个字节序列较为方便的被其他进程读取

##### 编码数据的格式有哪些

- 常用文本格式：JSON、XML。它们存在一些问题，例如XML 无法区分数字和字符串；JSON 无法区分整数和浮点数，且无法指定精度；二者都没有二进制编码，数据量一大冗余太多

- Thrift 与 Protocol Buffers

  - 使用IDL 来描述模式，编码时用标号标识字段名，从而节省空间
  - 旧代码读新数据：直接忽视新字段；新代码读旧数据：要求新字段必须是可选的或具有默认值

  > 这一块是我进了公司之后才比较熟悉的，不了解什么是IDL的同学可以直接搜一下，下面给出 IDL的 example。本质上就像一个契约，规定了1是username, 2是userid这样，传输的时候只传数字1和2即可；发送/接受的时候要编码/解码数据。

  ```idl
  struct Person {
      1: required string       userName,
      2: optional i64          favoriteNumber,
      3: optional list<string> interests
  }
  ```

- Avro

  - 产生原因：Thrift 不适合 Hadoop
  - 只存储字段数据类型以及其值，不包含标签号码。因此适用于动态类型的数据处理语言。

  ```idl
  record Person {
      string                userName;
      union { null, long }  favoriteNumber = null;
      array<string>         interests;
  }
  ```

  > 它序列化&反序列化的方式和 IDL很像。虽然失去了数字，但可以使用一个 byte 标识长度信息 or 使用 union 的哪个 branch，具体这个 byte 是啥含义就按照 IDL解析就好了嘛。

  - 具有读者模式和写者模式
    - 写者模式：应用程序可以使用它知道的任何模式编码数据
    - 读者模式：使用它知道的模式解码数据
    - 二者只需要兼容即可，非常宽松。如果发现读者模式中的字段在写者模式中没有，使用默认值填充；写者模式中多出来的字段直接忽略。
    - 为了保持兼容性，只能添加或删除具有默认值的字段
  - 如何存储写者模式：
    - 一种应用场景是批处理系统，该场景下数百万条数据具有相同的模式，单独弄一个文件记录模式即可；
  - 一种应用场景是数据库，可以给每个记录一个模式版本号，从而确定其模式
    - 一种应用场景是 RPC，可以在链接设置上协商模式版本
    - 合起来，从数据库构建数据仓库非常适合用 avro。因为数据库中有不同版本的数据，可以一次性将其转为新版本数据。

##### 数据流的类型有哪些

- 数据库中的数据流：写入数据库的时候对数据进行编码；读取的时候进行解码。
  - 可能存在数据丢失的问题。 e.g. 旧版本代码 A 读了新版本数据，修改后重写数据库，这中间会忽略新加的字段。
  - 数据库中可能存在好多好久以前的数据，通过重写的方式完成模式变更代价太大了，可选的方案是添加默认值为空的新列而不重写现有数据
- 服务中的数据流：RPC
  - 微服务架构：将大型应用程序按照功能区域分解为较小的服务。这个应用太广泛了
  - 遇到的问题：不可预测性；重试可能导致问题；传递较大的对象很昂贵
- 消息传递中的数据流：这里发送方不要求接收方给回应。

